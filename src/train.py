# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v3fWWBoUCwvZsyIy7Mmlyd4mmMeaQF2R
"""

import random
import numpy as np
import torch
from model import QuantumGCN
from data_prep import cora_dataset_preparation
from tqdm import tqdm


def set_seed(seed=42):
    # NumPy
    np.random.seed(seed)
    
    # Python Random
    random.seed(seed)
    
    # PyTorch
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # Ensure deterministic algorithms
    torch.use_deterministic_algorithms(True)

set_seed(53)

train_loader, test_loader, A_norm, len_test_dataset = cora_dataset_preparation()

device = torch.device("cpu")
model = QuantumGCN(8).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.CrossEntropyLoss()
A_norm = A_norm.to(device)


train_losses, test_accuracies = [], []

for epoch in range(60):
    model.train()
    total_loss = 0
    for batch_x, batch_y in tqdm(train_loader):
        batch_x, batch_y = batch_x.to(device), batch_y.to(device)
        optimizer.zero_grad()
        out = model(batch_x, A_norm)
        loss = criterion(out, batch_y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    train_losses.append(total_loss / len(train_loader))

    # Evaluate on test set
    model.eval()
    correct = 0
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x, batch_y = batch_x.to(device), batch_y.to(device)
            out = model(batch_x, A_norm)
            pred = out.argmax(dim=1)
            correct += (pred == batch_y).sum().item()
    accuracy = correct / len_test_dataset
    test_accuracies.append(accuracy)

    if epoch % 1 == 0:
        print(f"\nEpoch {epoch}: Loss = {train_losses[-1]:.4f}, Accuracy = {accuracy:.4f}")